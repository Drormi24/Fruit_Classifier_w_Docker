{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Study Objectives\nThis Notebook is a classification study on eyantra fruits dataset."},{"metadata":{},"cell_type":"markdown","source":"# Importing Python libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom sklearn import preprocessing, model_selection\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyper Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_split = 0.7\nEPOCHS = 13\ntrain_batch = 8\ntest_batch = 4\nlearning_rate = 0.001\nimage_size = 100\nclasses = ['Apple', 'Banana', 'Orange', 'Pineapple', 'Strawberry','Other']\nrate_gray = 0.2         # The rate of random images to be grayed by transformer\nrate_flip = 0.4         # The rate of random images to be horizontally fliped by transformer\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Images Data Entry and Preparations"},{"metadata":{"trusted":true},"cell_type":"code","source":"class IMG_Dataset(Dataset):\n    def __init__(self,file_name):\n        # Import data\n        filedata = pd.read_csv(file_name)\n        \n        # Train / Test split\n        trainset,testset = model_selection.train_test_split(\n                                                        filedata,\n                                                        train_size = train_split,\n                                                        random_state=11)\n        # Separate features from labels\n        x_train = trainset.iloc[:,:-1].values\n        x_test = testset.iloc[:,:-1].values\n        train_labels = trainset.iloc[:,-1].values\n        test_labels = testset.iloc[:,-1].values\n        \n        # Preprocess data before entering into net\n        scaler = preprocessing.StandardScaler()\n        x_train = scaler.fit_transform(x_train)\n        x_test = scaler.fit_transform(x_test)\n        \n        # Utilizing TorchVision transforms on random images to improve learning\n        transformer = torchvision.transforms.Compose([\n                                          transforms.RandomGrayscale(rate_gray),\n                                          transforms.RandomHorizontalFlip(rate_flip)])\n        x_train = torch.from_numpy(x_train).long()\n        x_train = transformer(x_train)\n        \n        # Prepare 4 datasets for Net processes\n        self.X_train = torch.tensor(x_train,\n                        dtype=torch.float32).reshape(-1,1,image_size,image_size)\n        self.X_test = torch.tensor(x_test,\n                        dtype=torch.float32).reshape(-1,1,image_size,image_size)\n        self.train_labels = torch.tensor(train_labels)\n        self.test_labels = torch.tensor(test_labels)\n        \n     \n    def __len__(self):\n        return len(self.train_labels)\n        \n    def __getitem__(self,index):\n        return self.X_train[index],self.train_labels[index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deep Learning net model based on LeNet5 model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel (G) of 100*100, 1 output channels\n        self.conv1 = nn.Conv2d(1, 1, 9)  #Conv. of 1*9*9 filter, 1 stride, 0 pads\n        self.conv2 = nn.Conv2d(1, 1, 15) #Conv. of 1*15*15 filter, 1 stride, 0 pads\n        self.fc1 = nn.Linear(16*16, 120)  #FC layer 16*16 to 120 nuerons\n        self.fc2 = nn.Linear(120, 84) #FC layer 120 to 84 nuerons\n        self.fc3 = nn.Linear(84, 6) # Output logits layer classes + 1 for noise\n        \n    def forward(self, x):\n        # input --> conv1-->tanh-->avg.Pool-->sigmoid-->conv2-->tanh-->avg.Pool\n        # -->sigmoid-->FC1-->tanh-->FC2-->tanh-->logits\n        # Average pooling over a (2, 2) window\n        x = F.sigmoid(F.max_pool2d(F.tanh(self.conv1(x)), (2, 2)))\n        x = F.sigmoid(F.max_pool2d(F.tanh(self.conv2(x)), 2))\n        x = x.view(-1, self.num_flat_features(x)) #Flatten features by batch\n        x = F.tanh(self.fc1(x))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x) \n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test validation runs the net after train phase with trained weights using predefined test dataloader and presenting images with their labeled class vs. predicted class "},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_validation():    \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, data in enumerate(testloader, 0):\n            org_data.X_test, org_data.test_labels = data\n            test_outputs = net(org_data.X_test)\n            _, predicted = torch.max(test_outputs.data, 1)\n            total += org_data.test_labels.size(0)\n            correct += (predicted == data[1]).sum().item()\n            if i % 60 == 59:\n                fig,ax = plt.subplots(1,test_batch)\n                plt.tight_layout(w_pad=2.0)\n                for img in range(len(data[1])):\n                    sample = torch.squeeze(data[0][img])\n                    label = data[1][img]\n                    ax[img].imshow(sample)\n                    ax[img].axis('off')\n                    ax[img].axes.get_xaxis().set_visible(False)\n                    ax[img].axes.get_yaxis().set_visible(False)\n                    ax[img].text(0,50,'{}'.format(classes[label]),color='white',fontweight='bold')\n                    ax[img].set_title('{}/{}: Predicted:\\n{}'.format(i+1,img+1,classes[predicted[img]]))   \n                plt.show()\n                \n    print('% Accuracy of the network on test images:', round(100 * correct / total,2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main Program\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    \n    #Create Train / Test DataLoaders\n    org_data = IMG_Dataset('dataset_attr.csv.zip')\n    trainloader = DataLoader(org_data, batch_size=train_batch,\n                             shuffle=True, num_workers=4)\n    testloader = DataLoader(org_data, batch_size=test_batch,\n                            shuffle=False, num_workers=4)\n     \n    \n    #Call LeNet5 Network and declare Loss criteria and Optimizing Method\n    net = Net()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n    loss_history = []\n    accuracy_history = []\n    #Training Main loop\n    for epoch in range(EPOCHS):  # loop over the dataset multiple times\n        running_loss = 0.0\n        total = 0\n        correct = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            # forward + backward + optimize\n            train_outputs = net(inputs)\n            _, predicted = torch.max(train_outputs.data, 1)\n            total = org_data.train_labels.size(0)\n            correct += (predicted == data[1]).sum().item()\n            loss = criterion(train_outputs, labels)\n            loss.backward()\n            optimizer.step()\n    \n            # print statistics\n            running_loss += loss.item()\n            if i % 100 == 99:    # print every 10 mini-batches\n                print('[%d, %5d] loss: %.3f ' %\n                      (epoch + 1, i + 1, running_loss))\n        loss_history.append(running_loss)\n        accuracy = 100*correct/total\n        accuracy_history.append(accuracy)\n        print('epoch',epoch+1,'completed with loss:',round(running_loss,3),' & accuracy[%]:',round(accuracy,2))\n    print('Finished Training')\n    \n    # Plot loss and accuracy progress during training phase\n    dx = range(EPOCHS)\n    headline1 = 'Cross-Entropy Loss w. Adam opt.(LR='+str(learning_rate)+')'\n    text1 = 'After '+str(EPOCHS)+' epochs, Loss is:'+str(round(loss_history[-1],3))\n    plt.plot(dx,loss_history,c='r',linewidth=4,label='Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title(headline1)\n    plt.text(int(EPOCHS/2),50,text1)\n    plt.show()\n    \n    headline2 = 'Accuracy w. Adam opt.(LR='+str(learning_rate)+')'\n    text2 = 'After '+str(EPOCHS)+' epochs, Accuracy is:'+str(round(accuracy_history[-1],2))\n    plt.plot(dx,accuracy_history,c='b',linewidth=4,label='Accuracy') \n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title(headline2)\n    plt.text(int(EPOCHS/2),90,text2)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Run validation on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_validation()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
